{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CE49X: Introduction to Computational Thinking and Data Science for Civil Engineers\n## Week 1 — Theory: The Data Science Lifecycle\n\n**Instructor:** Dr. Eyuphan Koc  \n**Department of Civil Engineering, Bogazici University**  \n**Semester:** Spring 2026\n\n*Companion notebook to Week 1 lecture — designed for in-class discussion*\n\n---\n\n## Table of Contents\n\n1. [The Question Comes First](#1.-The-Question-Comes-First)\n2. [Data Collection & Quality](#2.-Data-Collection-&-Quality)\n3. [Exploratory Data Analysis (EDA)](#3.-Exploratory-Data-Analysis-(EDA))\n4. [Feature Engineering](#4.-Feature-Engineering)\n5. [Modeling](#5.-Modeling)\n6. [Evaluation & Communication](#6.-Evaluation-&-Communication)\n7. [Reflection](#7.-Reflection)",
   "id": "8b5e6084"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Question Comes First\n",
    "\n",
    "**Scenario:** A construction site has **200 concrete cylinder test results**. Each sample was tested at 7 days and again at 28 days after casting. The site engineer asks:\n",
    "\n",
    "> *\"Can we predict 28-day compressive strength from 7-day tests?\"*\n",
    "\n",
    "If the answer is yes, the construction team could make earlier decisions about concrete quality — potentially saving weeks of waiting time and avoiding costly rework.\n",
    "\n",
    "Let's walk through the **entire data science lifecycle** using this real-world civil engineering problem."
   ],
   "id": "8378e9a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulated concrete cylinder test data\n",
    "n = 200\n",
    "cement_content = np.random.uniform(280, 400, n)  # kg/m³\n",
    "water_cement = np.random.uniform(0.35, 0.60, n)\n",
    "age_7d_strength = 10 + 0.05 * cement_content - 15 * water_cement + np.random.normal(0, 2, n)\n",
    "age_28d_strength = 1.3 * age_7d_strength + 5 + np.random.normal(0, 3, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sample_id': [f'C{i+1:03d}' for i in range(n)],\n",
    "    'cement_kg_m3': np.round(cement_content, 1),\n",
    "    'water_cement_ratio': np.round(water_cement, 3),\n",
    "    'strength_7d_MPa': np.round(age_7d_strength, 1),\n",
    "    'strength_28d_MPa': np.round(age_28d_strength, 1)\n",
    "})\n",
    "\n",
    "# Inject real-world data quality issues\n",
    "df.loc[15, 'strength_28d_MPa'] = 900.0  # Typo: 900 instead of 30\n",
    "df.loc[42, 'strength_7d_MPa'] = np.nan  # Missing value\n",
    "df.loc[87, 'strength_7d_MPa'] = np.nan\n",
    "df.loc[120, 'strength_28d_MPa'] = np.nan\n",
    "df.loc[55, 'cement_kg_m3'] = -320  # Negative value error\n",
    "df = pd.concat([df, df.iloc[[10, 10, 73]]], ignore_index=True)  # Duplicate rows\n",
    "\n",
    "print(f\"Dataset: {len(df)} rows × {df.shape[1]} columns\")\n",
    "df.head(10)"
   ],
   "id": "55b55db6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[DISCUSS] Look at the data above.**\n",
    "> - What columns do we have?\n",
    "> - What would you need to know before building a model?\n",
    "> - Can you spot any problems just from the first 10 rows?"
   ],
   "id": "9ef45ed1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight: A data science project starts with a question, not with code.**\n",
    "> The engineer's question — \"Can we predict 28-day strength from 7-day tests?\" — drives every decision that follows.\n",
    "\n",
    "### The CRISP-DM Framework\n",
    "\n",
    "The standard data science workflow:\n",
    "\n",
    "```\n",
    "Business Understanding → Data Understanding → Data Preparation\n",
    "        ↑                                          ↓\n",
    "    Deployment    ←    Evaluation    ←    Modeling\n",
    "```\n",
    "\n",
    "Each stage informs the next, and the process is **iterative** — you often loop back to earlier stages."
   ],
   "id": "83cd87ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Collection & Quality\n",
    "\n",
    "Before doing anything fancy, we need to **understand** and **trust** our data. This stage is often called *data profiling* or *data auditing*."
   ],
   "id": "f156eecc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TOGETHER] Run these inspection commands — what do they reveal?\n",
    "print(\"=== Data Types ===\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\n=== Shape: {df.shape} ===\")\n",
    "print(f\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\n=== Basic Statistics ===\")\n",
    "df.describe()"
   ],
   "id": "213c2516"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[DISCUSS] What did you notice?**\n",
    "> - `describe()` shows max `strength_28d_MPa` = 900 MPa. Concrete maxes out around 100 MPa. That's a data entry error.\n",
    "> - There are missing values in strength columns.\n",
    "> - We have 203 rows when we expected 200 — duplicates?\n",
    "> - A negative cement content value? That's physically impossible.\n",
    "\n",
    "> **Key Insight: Garbage In, Garbage Out**\n",
    "> No model can overcome bad data. Data quality determines model quality."
   ],
   "id": "230b0b68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Model on dirty data\n",
    "X_dirty = df[['strength_7d_MPa']].dropna()\n",
    "y_dirty = df.loc[X_dirty.index, 'strength_28d_MPa'].values\n",
    "X_dirty = X_dirty.values\n",
    "mask = ~np.isnan(y_dirty)\n",
    "X_dirty, y_dirty = X_dirty[mask], y_dirty[mask]\n",
    "\n",
    "model_dirty = LinearRegression().fit(X_dirty, y_dirty)\n",
    "\n",
    "# Clean the data\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.drop_duplicates(subset='sample_id')\n",
    "df_clean = df_clean[df_clean['strength_28d_MPa'] < 200]  # Remove 900 MPa outlier\n",
    "df_clean = df_clean[df_clean['cement_kg_m3'] > 0]  # Remove negative values\n",
    "df_clean = df_clean.dropna(subset=['strength_7d_MPa', 'strength_28d_MPa'])\n",
    "\n",
    "X_clean = df_clean[['strength_7d_MPa']].values\n",
    "y_clean = df_clean['strength_28d_MPa'].values\n",
    "model_clean = LinearRegression().fit(X_clean, y_clean)\n",
    "\n",
    "# Compare predictions\n",
    "test_point = np.array([[20.0]])\n",
    "print(f\"Dirty model predicts: {model_dirty.predict(test_point)[0]:.1f} MPa for 7-day strength of 20 MPa\")\n",
    "print(f\"Clean model predicts: {model_clean.predict(test_point)[0]:.1f} MPa for 7-day strength of 20 MPa\")\n",
    "print(f\"\\nDirty model R²: {model_dirty.score(X_dirty, y_dirty):.3f}\")\n",
    "print(f\"Clean model R²: {model_clean.score(X_clean, y_clean):.3f}\")"
   ],
   "id": "1be75573"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dirty model's R² is much lower, and its predictions are unreliable. **One outlier (900 MPa) distorted the entire regression line.**\n",
    "\n",
    "> **Key Insight: Data Provenance**\n",
    "> Always ask: *Where did this data come from? Who collected it? What instruments were used? Can we trust it?*\n",
    "> In our case, the 900 MPa value was likely a data entry error (perhaps 30.0 mistyped as 900)."
   ],
   "id": "ae769f79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original dataset:  {len(df)} rows\")\n",
    "print(f\"After dedup:       {len(df.drop_duplicates(subset='sample_id'))} rows\")\n",
    "print(f\"After outlier fix: removed 1 row (900 MPa)\")\n",
    "print(f\"After neg fix:     removed 1 row (negative cement)\")\n",
    "print(f\"After dropna:      {len(df_clean)} rows\")\n",
    "print(f\"\\nClean dataset ready for analysis: {len(df_clean)} rows × {df_clean.shape[1]} columns\")"
   ],
   "id": "05f64315"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA is the **detective work** of data science. Before we build any model, we need to *see* our data — its distributions, relationships, and anomalies.\n",
    "\n",
    "> **Definition: Exploratory Data Analysis (EDA)**\n",
    "> A systematic approach to understanding the main characteristics of a dataset, primarily through visualization and summary statistics, before formal modeling begins."
   ],
   "id": "f2141f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df_clean['strength_28d_MPa'], bins=25, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('28-day Strength (MPa)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of 28-day Compressive Strength', fontsize=13)\n",
    "axes[0].axvline(df_clean['strength_28d_MPa'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {df_clean['strength_28d_MPa'].mean():.1f} MPa\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(df_clean['strength_7d_MPa'], bins=25, edgecolor='black', alpha=0.7, color='indianred')\n",
    "axes[1].set_xlabel('7-day Strength (MPa)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of 7-day Compressive Strength', fontsize=13)\n",
    "axes[1].axvline(df_clean['strength_7d_MPa'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {df_clean['strength_7d_MPa'].mean():.1f} MPa\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d2cc5226"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[DISCUSS] Look at the histograms.**\n",
    "> - What is the shape of the distributions? Are they roughly symmetric or skewed?\n",
    "> - What is the typical range of 28-day strength values?\n",
    "> - Do the distributions look approximately normal? Why might that matter?"
   ],
   "id": "99c42898"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(df_clean['strength_7d_MPa'], df_clean['strength_28d_MPa'], alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "ax.set_xlabel('7-day Strength (MPa)', fontsize=12)\n",
    "ax.set_ylabel('28-day Strength (MPa)', fontsize=12)\n",
    "ax.set_title('7-day vs 28-day Compressive Strength', fontsize=13)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3ef9b962"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[DISCUSS] The scatter plot tells a story.**\n",
    "> - Is there a clear trend? What kind of relationship does this look like — linear, curved, or no pattern?\n",
    "> - Are there any outliers or unusual points?\n",
    "> - Based on this plot alone, do you think we can build a useful predictive model?"
   ],
   "id": "bd072f18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "corr = df_clean[['cement_kg_m3', 'water_cement_ratio', 'strength_7d_MPa', 'strength_28d_MPa']].corr()\n",
    "im = ax.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(corr.columns)))\n",
    "ax.set_yticks(range(len(corr.columns)))\n",
    "ax.set_xticklabels(['Cement', 'W/C Ratio', '7d Str', '28d Str'], rotation=45, ha='right')\n",
    "ax.set_yticklabels(['Cement', 'W/C Ratio', '7d Str', '28d Str'])\n",
    "for i in range(len(corr)):\n",
    "    for j in range(len(corr)):\n",
    "        ax.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.set_title('Correlation Matrix', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "11820e18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight: EDA is Detective Work**\n",
    "> Before building any model, you must *see* your data. Visualizations reveal patterns, outliers, and relationships that summary statistics alone can miss.\n",
    "\n",
    "> **[QUICK] Which feature has the strongest correlation with 28-day strength?**\n",
    "> - Look at the bottom row of the correlation matrix.\n",
    "> - Is it 7-day strength, cement content, or water-cement ratio?\n",
    "> - Does this make physical sense?"
   ],
   "id": "fb737165"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anscombe's Quartet — four datasets with IDENTICAL statistics\n",
    "anscombe_x = [\n",
    "    [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n",
    "    [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n",
    "    [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n",
    "    [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\n",
    "]\n",
    "anscombe_y = [\n",
    "    [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68],\n",
    "    [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74],\n",
    "    [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73],\n",
    "    [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    x = np.array(anscombe_x[idx])\n",
    "    y = np.array(anscombe_y[idx])\n",
    "    ax.scatter(x, y, s=60, edgecolors='k', alpha=0.8)\n",
    "    # Fit line\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    x_line = np.linspace(3, 20, 100)\n",
    "    ax.plot(x_line, m * x_line + b, 'r--', linewidth=2)\n",
    "    ax.set_title(f'Dataset {idx + 1}: mean(x)={x.mean():.1f}, mean(y)={y.mean():.2f}, r={np.corrcoef(x, y)[0,1]:.2f}', fontsize=10)\n",
    "    ax.set_xlim(3, 20)\n",
    "    ax.set_ylim(2, 14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Anscombe's Quartet: Same Statistics, Different Stories\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "03163487"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four datasets above have **nearly identical** means, variances, correlations, and regression lines — yet they tell completely different stories. This is why we **never skip visualization**.\n",
    "\n",
    "> **Key Insight: Correlation is Not Causation**\n",
    "> A classic example from civil engineering: both *ice cream sales* and *bridge expansion joint failures* increase in summer. They are correlated — but ice cream doesn't cause bridge failures. Temperature is the **confounding variable** driving both.\n",
    ">\n",
    "> Always ask: is there a plausible *causal mechanism*, or just a statistical association?"
   ],
   "id": "45ba69ce"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering\n",
    "\n",
    "Feature engineering is the process of creating new input variables from existing data. This is where **domain expertise** becomes a superpower.\n",
    "\n",
    "> **Definition: Feature Engineering**\n",
    "> The process of using domain knowledge to create new variables (features) that make machine learning models more effective."
   ],
   "id": "2df8bc4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering — adding domain knowledge\n",
    "df_clean = df_clean.copy()\n",
    "df_clean['strength_gain_rate'] = df_clean['strength_28d_MPa'] / df_clean['strength_7d_MPa']\n",
    "df_clean['cement_efficiency'] = df_clean['strength_28d_MPa'] / df_clean['cement_kg_m3']\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(f\"  strength_gain_rate — how much strength grows from 7 to 28 days\")\n",
    "print(f\"  cement_efficiency — strength per kg of cement\")\n",
    "print(f\"\\nSample values:\")\n",
    "df_clean[['sample_id', 'strength_7d_MPa', 'strength_28d_MPa', 'strength_gain_rate', 'cement_efficiency']].head()"
   ],
   "id": "c369d4c0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Example: Civil Engineering**\n",
    "> A data scientist might use `cement_kg_m3` and `water_cement_ratio` as separate features. But a civil engineer knows that the *interaction* between water and cement (i.e., `water_cement_ratio * cement_kg_m3` = total water content) is physically meaningful. This kind of domain-informed feature often improves model performance significantly.\n",
    "\n",
    "> **[PRACTICE] Think of other features you could derive:**\n",
    "> - What about the ratio of 7-day to 28-day strength? (already created above)\n",
    "> - Could temperature or curing conditions matter? (yes, but not in our dataset)\n",
    "> - What about cement type or aggregate properties?"
   ],
   "id": "c0b2fe06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Raw features\n",
    "X_raw = df_clean[['strength_7d_MPa', 'cement_kg_m3', 'water_cement_ratio']].values\n",
    "y = df_clean['strength_28d_MPa'].values\n",
    "\n",
    "# Engineered features (add ratio and interaction)\n",
    "X_eng = df_clean[['strength_7d_MPa', 'cement_kg_m3', 'water_cement_ratio']].copy()\n",
    "X_eng['wc_x_cement'] = df_clean['water_cement_ratio'] * df_clean['cement_kg_m3']\n",
    "X_eng['strength_7d_sq'] = df_clean['strength_7d_MPa'] ** 2\n",
    "X_eng = X_eng.values\n",
    "\n",
    "model_raw = LinearRegression()\n",
    "model_eng = LinearRegression()\n",
    "\n",
    "scores_raw = cross_val_score(model_raw, X_raw, y, cv=5, scoring='r2')\n",
    "scores_eng = cross_val_score(model_eng, X_eng, y, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"Raw features    — Mean R²: {scores_raw.mean():.3f} (±{scores_raw.std():.3f})\")\n",
    "print(f\"Engineered feat — Mean R²: {scores_eng.mean():.3f} (±{scores_eng.std():.3f})\")"
   ],
   "id": "151e0a9d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight: Feature Engineering is Where Domain Knowledge Meets Data Science**\n",
    "> A civil engineer can create features — like the water-cement interaction or strength gain rate — that a generic data scientist wouldn't think of. This is your competitive advantage."
   ],
   "id": "c51417b3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Modeling\n",
    "\n",
    "Now we build a predictive model. The golden rule:\n",
    "\n",
    "> **Key Insight: Start Simple**\n",
    "> Begin with the simplest model that could work. If linear regression gives you R² = 0.90, you may not need a neural network. Simple models are easier to explain, debug, and trust."
   ],
   "id": "03172d45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean[['strength_7d_MPa']].values\n",
    "y = df_clean['strength_28d_MPa'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model: strength_28d = {model.coef_[0]:.2f} × strength_7d + {model.intercept_:.2f}\")\n",
    "print(f\"Train R²: {model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test R²:  {model.score(X_test, y_test):.3f}\")"
   ],
   "id": "f8497b97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predicted vs actual\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "lims = [min(y_test.min(), y_pred.min()) - 2, max(y_test.max(), y_pred.max()) + 2]\n",
    "axes[0].plot(lims, lims, 'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual 28-day Strength (MPa)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted 28-day Strength (MPa)', fontsize=12)\n",
    "axes[0].set_title('Predicted vs Actual', fontsize=13)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted 28-day Strength (MPa)', fontsize=12)\n",
    "axes[1].set_ylabel('Residual (MPa)', fontsize=12)\n",
    "axes[1].set_title('Residuals Plot', fontsize=13)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "55314a70"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[DISCUSS] Look at the residuals plot.**\n",
    "> - Are the errors randomly scattered? Or do you see a pattern?\n",
    "> - If there's a pattern, the model is missing something. What could it be?\n",
    "\n",
    "> **Key Insight: Start Simple**\n",
    "> A simple model you understand beats a complex model you don't. Linear regression is interpretable: \"For every 1 MPa increase in 7-day strength, 28-day strength increases by about X MPa.\""
   ],
   "id": "0d1a45fc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluation & Communication\n",
    "\n",
    "A model is only useful if its performance is **adequate for the application** and its results can be **communicated clearly** to decision-makers (engineers, project managers, clients)."
   ],
   "id": "b6e40bde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== Model Performance in Engineering Terms ===\\n\")\n",
    "print(f\"  R² = {r2:.3f}\")\n",
    "print(f\"    → The model explains {r2*100:.1f}% of the variation in 28-day strength.\\n\")\n",
    "print(f\"  MAE = {mae:.1f} MPa\")\n",
    "print(f\"    → Predictions are off by about {mae:.1f} MPa on average.\\n\")\n",
    "print(f\"  RMSE = {rmse:.1f} MPa\")\n",
    "print(f\"    → Typical prediction error is about {rmse:.1f} MPa.\\n\")\n",
    "print(f\"  Is this acceptable? It depends on the application:\")\n",
    "print(f\"    - Quality control (pass/fail at 30 MPa): ±{mae:.1f} MPa matters near the threshold\")\n",
    "print(f\"    - Mix design optimization: probably acceptable\")\n",
    "print(f\"    - Structural load rating: need to consider safety factors\")"
   ],
   "id": "46347bef"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight: Metrics Must Be Interpreted in Context**\n",
    "> \"95% accuracy\" means nothing without knowing the stakes. An MAE of 3 MPa might be excellent for mix design but dangerous for structural load rating."
   ],
   "id": "78373d36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a borderline sample — close to the pass/fail threshold of 30 MPa\n",
    "threshold = 30.0  # MPa\n",
    "borderline_mask = np.abs(y_test - threshold) < 3\n",
    "borderline_idx = np.where(borderline_mask)[0]\n",
    "\n",
    "if len(borderline_idx) > 0:\n",
    "    idx = borderline_idx[0]\n",
    "    print(f\"Sample near the pass/fail threshold ({threshold} MPa):\")\n",
    "    print(f\"  7-day strength: {X_test[idx, 0]:.1f} MPa\")\n",
    "    print(f\"  Actual 28-day:  {y_test[idx]:.1f} MPa\")\n",
    "    print(f\"  Predicted 28-day: {y_pred[idx]:.1f} MPa\")\n",
    "    print(f\"  Actual status:    {'PASS' if y_test[idx] >= threshold else 'FAIL'}\")\n",
    "    print(f\"  Predicted status: {'PASS' if y_pred[idx] >= threshold else 'FAIL'}\")\n",
    "    if (y_pred[idx] >= threshold) != (y_test[idx] >= threshold):\n",
    "        print(f\"\\n  ⚠ WRONG CALL! The model got this one wrong.\")\n",
    "        print(f\"  What's the cost of this error?\")\n",
    "else:\n",
    "    print(\"No borderline samples found in the test set near 30 MPa.\")"
   ],
   "id": "c79f8948"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight: The Workflow is Iterative**\n",
    "> After seeing model results, you often return to earlier stages:\n",
    "> - Poor R²? → Go back to EDA, look for nonlinear patterns\n",
    "> - Residuals show a pattern? → Try feature engineering\n",
    "> - Model fails on borderline cases? → Consider different evaluation metrics\n",
    ">\n",
    "> Data science is a cycle, not a conveyor belt."
   ],
   "id": "80fb7f49"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Reflection\n",
    "\n",
    "Let's step back and see the full picture of what we've done — and how each stage connects to the next."
   ],
   "id": "a4ef577c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Full Lifecycle — Revisited\n",
    "\n",
    "| Stage | What You Do | Key Question |\n",
    "|---|---|---|\n",
    "| **1. Business Understanding** | Define the problem | What question am I answering? |\n",
    "| **2. Data Understanding** | Inspect, profile, explore | Is my data trustworthy? |\n",
    "| **3. Data Preparation** | Clean, transform, engineer features | What does the model need? |\n",
    "| **4. Modeling** | Fit, predict | What's the simplest model that works? |\n",
    "| **5. Evaluation** | Measure, interpret | Is this good enough for the application? |\n",
    "| **6. Deployment** | Communicate, integrate | Who uses this and how? |\n",
    "\n",
    "> **[DISCUSS] Which stage takes the most time in practice?**\n",
    "> Studies consistently show that **data cleaning and preparation** consume 60–80% of a data scientist's time. The modeling step — the \"sexy\" part — is often the quickest."
   ],
   "id": "40742fd5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways from Today\n",
    "\n",
    "1. **Start with a question.** The problem defines the project, not the algorithm.\n",
    "2. **Trust your data — but verify.** Garbage in, garbage out.\n",
    "3. **Visualize before you model.** Anscombe's Quartet proves that statistics alone can be misleading.\n",
    "4. **Domain knowledge is your superpower.** Feature engineering is where civil engineers outperform generic data scientists.\n",
    "5. **Start simple.** Interpretable models build trust and reveal problems early.\n",
    "6. **Context determines quality.** A 3 MPa error is acceptable for some tasks and catastrophic for others.\n",
    "7. **Iterate.** The lifecycle is a loop, not a straight line."
   ],
   "id": "bc23f226"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Connection to the CE49X Course\n\n- **Week 01**: Python foundations (self-study) + the data science lifecycle (this notebook, in-class)\n- **Week 02**: Modules, packages, and data science libraries\n- **Weeks 03-04**: NumPy, Pandas, Matplotlib → Stages 2-3 (data understanding, EDA, visualization)\n- **Weeks 05-06**: Statistical analysis, intro to ML → Stages 4-5 (modeling, evaluation)\n- **Weeks 07-08**: Naive Bayes, SVM → Advanced modeling + evaluation philosophy\n\nEvery week builds on the lifecycle you learned today.\n\n---\n\n### Questions?\n\n**Dr. Eyuphan Koc**  \neyuphan.koc@bogazici.edu.tr",
   "id": "05e451f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}